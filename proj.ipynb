{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3a52d395",
      "metadata": {},
      "source": [
        "# Projeto de Engenharia do Conhecimento 2023/2024\n",
        "\n",
        "*Projeto by: Renato Ferreira (58238), Pedro Lopes(58196), Simão Quintas (58190)*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bfdaccd",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, matthews_corrcoef, make_scorer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b69ae97",
      "metadata": {},
      "source": [
        "Let's drop the rows and columns with a large number of NA values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ae247e",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv('proj-data.csv', na_values='?')\n",
        "\n",
        "# Remover as colunas que indicam se algo foi medido ou não, a coluna com a indentificação e colunas com muitos valores ausentes\n",
        "data.drop(data.filter(like='measured').columns, axis=1, inplace=True)\n",
        "data.drop('[record identification]', axis=1, inplace=True)\n",
        "data.drop('referral source:',axis=1,inplace=True)\n",
        "\n",
        "hyperthyroid_conditions = ['A', 'B', 'C', 'D']\n",
        "hypothyroid_conditions = ['E', 'F', 'G', 'H']\n",
        "binding_protein = ['I', 'J']\n",
        "general_health = ['K']\n",
        "replacement_therapy = ['L', 'M', 'N']\n",
        "discordant = ['R']\n",
        "none = ['-']\n",
        "\n",
        "for i in range(len(data)):\n",
        "    if data.at[i, \"diagnoses\"] in hyperthyroid_conditions :\n",
        "        data.at[i, \"diagnoses\"] = 1\n",
        "    elif data.at[i, \"diagnoses\"] in hypothyroid_conditions :\n",
        "        data.at[i, \"diagnoses\"] = 2\n",
        "    elif data.at[i, \"diagnoses\"] in binding_protein :\n",
        "        data.at[i, \"diagnoses\"] = 3\n",
        "    elif data.at[i, \"diagnoses\"] in general_health :\n",
        "        data.at[i, \"diagnoses\"] = 4\n",
        "    elif data.at[i, \"diagnoses\"] in replacement_therapy :\n",
        "        data.at[i, \"diagnoses\"] = 5\n",
        "    elif data.at[i, \"diagnoses\"] in discordant :\n",
        "        data.at[i, \"diagnoses\"] = 6\n",
        "    elif data.at[i, \"diagnoses\"] in none :\n",
        "        data.at[i, \"diagnoses\"] = 7 \n",
        "    else:\n",
        "        data.at[i, \"diagnoses\"] = 8 \n",
        "\n",
        "data.replace('f', 0, inplace=True)\n",
        "data.replace('t', 1, inplace=True)\n",
        "data.replace('F', 0, inplace=True)\n",
        "data.replace('M', 1, inplace=True)\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb4bdddd",
      "metadata": {},
      "source": [
        "Obter os valores da feature matrix tratados e da target variable, removendo as colunas com poucos valores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea2fb48",
      "metadata": {},
      "outputs": [],
      "source": [
        "missingValues = {}\n",
        "\n",
        "for i in data.values:\n",
        "  c=0\n",
        "  for j in i:\n",
        "    if pd.isna(j):\n",
        "      if data.columns[c] not in missingValues:\n",
        "        missingValues[data.columns[c]] = 1\n",
        "      else:\n",
        "        missingValues[data.columns[c]] += 1\n",
        "    c+=1\n",
        "\n",
        "for c in missingValues.keys():\n",
        "  if missingValues[c] > 0:\n",
        "    print(c,str(missingValues[c]),\"missing values!\")\n",
        "\n",
        "X = data.iloc[:,:-1]\n",
        "\n",
        "y = data.iloc[: , -1:]\n",
        "y = y.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "177c91c9",
      "metadata": {},
      "source": [
        "Vamos avaliar a importância de T3 e de TBG, de forma a avaliar se os removemos ou não."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2725fe8",
      "metadata": {},
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ebd5bc5",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=0)\n",
        "\n",
        "#SCALER\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "Xt_train=scaler.fit_transform(X_train)\n",
        "Xt_test=scaler.fit_transform(X_test)\n",
        "\n",
        "#FEATURE SELECTION\n",
        "N,M = Xt_train.shape\n",
        "\n",
        "rfr=RandomForestRegressor(random_state=0)\n",
        "sel = SelectFromModel(estimator=rfr,threshold=0.02)\n",
        "y_train = y_train.squeeze().ravel()\n",
        "y_test = y_test.squeeze().ravel()\n",
        "sel.fit(Xt_train, y_train)\n",
        "\n",
        "print(\"Default threshold: \", sel.threshold_)\n",
        "\n",
        "features=sel.get_support()\n",
        "Features_selected =np.arange(M)[features]\n",
        "\n",
        "print(\"The features selected are columns: \", Features_selected)\n",
        "\n",
        "nX_train=sel.transform(Xt_train)\n",
        "nX_test=sel.transform(Xt_test)\n",
        "\n",
        "score = make_scorer(matthews_corrcoef)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d12a6a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier(random_state=123)      \n",
        "rfc.fit(Xt_train, y_train)\n",
        "\n",
        "# Calculate feature importances and standard deviations\n",
        "importances = rfc.feature_importances_\n",
        "std = np.std([t.feature_importances_ for t in rfc.estimators_], axis=0)\n",
        "\n",
        "# Sort features based on importances\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print and plot feature importances with error bars\n",
        "print(\"Feature Importances:\")\n",
        "for f in range(Xt_train.shape[1]):\n",
        "    print(\"%d: Feature %d (%f ± %f)\" % (f + 1, indices[f], importances[indices[f]], std[indices[f]]))\n",
        "    \n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(Xt_train.shape[1]), importances[indices], color=\"b\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(Xt_train.shape[1]), X.columns[indices], rotation=90)\n",
        "plt.xlim([-1, Xt_train.shape[1]])\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.title(\"Feature Importances with Error Bars\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff275eb4",
      "metadata": {},
      "source": [
        "# Métodos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59e5daae",
      "metadata": {},
      "outputs": [],
      "source": [
        "def present_statistics(y_test, preds):\n",
        "    print(\"Statistics:\")\n",
        "    print(\"The Precision is: %7.4f\" % precision_score(y_test, preds, average='weighted'))\n",
        "    print(\"The Accuracy is: %7.4f\" % accuracy_score(y_test, preds))\n",
        "    print(\"The Recall is: %7.4f\" % recall_score(y_test, preds, average='weighted'))\n",
        "    print(\"The F1 score is: %7.4f\" % f1_score(y_test, preds, average='weighted'))\n",
        "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(y_test, preds))\n",
        "    print(\"-------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d212e6b8",
      "metadata": {},
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34616025",
      "metadata": {},
      "source": [
        "### Testar o modelo Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c4d0cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "print(\"Com valores Nan, sem scaler:\")\n",
        "\n",
        "# Create and train the DecisionTreeClassifier model\n",
        "tree_model = DecisionTreeClassifier()\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "tree_preds = tree_model.predict(X_test)\n",
        "present_statistics(y_test, tree_preds)\n",
        "\n",
        "print(\"Sem valores Nan, sem scaler:\")\n",
        "\n",
        "# Create an instance of the SimpleImputer class with fill_value='-1'\n",
        "imputer = SimpleImputer(strategy='constant', fill_value=-1)\n",
        "\n",
        "# Replace missing values with -1 in the training and testing data\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "# Train the DecisionTreeClassifier model with the simple imputer\n",
        "tree_model.fit(X_train_imputed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "tree_preds = tree_model.predict(X_test_imputed)\n",
        "present_statistics(y_test, tree_preds)\n",
        "\n",
        "print(\"Com valores Nan, com scaler:\")\n",
        "\n",
        "# Train the DecisionTreeClassifier model with the simple imputer\n",
        "tree_model.fit(Xt_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "tree_preds = tree_model.predict(Xt_test)\n",
        "present_statistics(y_test, tree_preds)\n",
        "\n",
        "print(\"Sem valores Nan, com scaler:\")\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "tree_model.fit(X_train_imputed, y_train)\n",
        "\n",
        "tree_preds = tree_model.predict(X_test_imputed)\n",
        "present_statistics(y_test, tree_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0411e95c",
      "metadata": {},
      "source": [
        "Os resultados ao utilizar valores Nan são melhores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c41ab4ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_flat = np.ravel(y_train)\n",
        "y_test_flat = np.ravel(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf2f559b",
      "metadata": {},
      "source": [
        "## KNeighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02fdfd13",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "print(\"Usando um scaler:\")\n",
        "\n",
        "# Replace missing values with -1 in the scaled training and testing data\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "knn_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "# Predictions\n",
        "knn_preds = knn_model.predict(X_test_imputed)\n",
        "present_statistics(y_test, knn_preds)\n",
        "\n",
        "print(\"Sem usar scaler:\")\n",
        "\n",
        "# Replace missing values with -1 in the training and testing data\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "knn_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "# Predictions\n",
        "knn_preds = knn_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, knn_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bc842a5",
      "metadata": {},
      "source": [
        "É melhor ao usar um scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f97f89c",
      "metadata": {},
      "source": [
        "## SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "897724dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "svc_model = SVC()\n",
        "\n",
        "print(svc_model,\"usando scaler:\")\n",
        "# Replace missing values with -1 in the training and testing data\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "svc_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "svc_preds = svc_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, svc_preds)\n",
        "\n",
        "print(svc_model,\"sem scaler:\")\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "svc_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "svc_preds = svc_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, svc_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6381e11c",
      "metadata": {},
      "source": [
        "## Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8627910d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gaus_model = GaussianNB()\n",
        "\n",
        "print(gaus_model,\"sem scaler:\")\n",
        "\n",
        "# Replace missing values with -1 in the training and testing data\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "gaus_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "gaus_preds = gaus_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, gaus_preds)\n",
        "\n",
        "print(gaus_model,\"com scaler:\")\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "gaus_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "gaus_preds = gaus_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, gaus_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83936bfe",
      "metadata": {},
      "source": [
        "## LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f89254",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logr_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "print(logr_model,\"com scaler:\")\n",
        "\n",
        "# Replace missing values with -1 in the training and testing data\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "# Train models\n",
        "logr_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "logr_preds = logr_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, logr_preds)\n",
        "\n",
        "print(logr_model,\"sem scaler:\")\n",
        "\n",
        "# Replace missing values with -1 in the training and testing data\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "# Train models\n",
        "logr_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "logr_preds = logr_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, logr_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa7c6498",
      "metadata": {},
      "source": [
        "Os melhores modelos são o Decision Tree, KNeighbors e LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75163cfc",
      "metadata": {},
      "source": [
        "## Model Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a05b584b",
      "metadata": {},
      "source": [
        "### Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "995c07b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'max_depth': [None,*range(3, 30)],\n",
        "    'min_samples_split': [*range(2,15)],\n",
        "    'min_samples_leaf': [*range(2,15)],\n",
        "    'max_features': [None],\n",
        "    'criterion': ['gini','entropy']\n",
        "}\n",
        "\n",
        "tree_model = DecisionTreeClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(estimator=tree_model, param_grid=param_grid, cv=5, scoring='f1_macro')\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_tree_model = grid_search.best_estimator_\n",
        "\n",
        "tree_preds = best_tree_model.predict(X_test)\n",
        "\n",
        "present_statistics(y_test, tree_preds)\n",
        "\n",
        "# Perform cross-validation with the best estimator\n",
        "cv_scores = cross_val_score(best_tree_model, X_train, y_train, cv=5, scoring='f1_macro')\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean Cross-Validation Score:\", cv_scores.mean())\n",
        "print(\"Standard Deviation of Cross-Validation Score:\", cv_scores.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36575ef1",
      "metadata": {},
      "source": [
        "### KNeighbours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3760f466",
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_neighbors': [3,5,7,9,11,13,15,17],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
        "}\n",
        "\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=5, scoring='f1_weighted')\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "grid_search.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_knn_model = grid_search.best_estimator_\n",
        "\n",
        "knn_preds = best_knn_model.predict(X_test_imputed)\n",
        "\n",
        "present_statistics(y_test_flat, knn_preds)\n",
        "\n",
        "# Perform cross-validation with the best estimator\n",
        "cv_scores = cross_val_score(best_knn_model, X_train_imputed, y_train_flat, cv=5, scoring='f1_macro')\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean Cross-Validation Score:\", cv_scores.mean())\n",
        "print(\"Standard Deviation of Cross-Validation Score:\", cv_scores.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77482137",
      "metadata": {},
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19e3929b",
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "logreg_model = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\n",
        "\n",
        "grid_search = GridSearchCV(estimator=logreg_model, param_grid=param_grid, cv=5, scoring='f1_weighted')\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "grid_search.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_logreg_model = grid_search.best_estimator_\n",
        "\n",
        "logreg_preds = best_logreg_model.predict(X_test_imputed)\n",
        "\n",
        "present_statistics(y_test_flat, logreg_preds)\n",
        "\n",
        "# Perform cross-validation with the best estimator\n",
        "cv_scores = cross_val_score(best_logreg_model, X_train_imputed, y_train_flat, cv=5, scoring='f1_macro')\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean Cross-Validation Score:\", cv_scores.mean())\n",
        "print(\"Standard Deviation of Cross-Validation Score:\", cv_scores.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b56c4245",
      "metadata": {},
      "source": [
        "Escolhemos o Decision Tree com os parâmetros:\n",
        "'criterion': 'gini', \n",
        "'max_depth': 17, \n",
        "'max_features': None, \n",
        "'min_samples_leaf': 3, \n",
        "'min_samples_split': 10, por ter sido aquele com melhor cross-validation score e com menor standard deviation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31d0cb85",
      "metadata": {},
      "source": [
        "# O2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8db72f60",
      "metadata": {},
      "source": [
        "## Idade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adfb6ea2",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "#OBJETIVO 2 : IDADE\n",
        "\n",
        "data_age = pd.read_csv('proj-data.csv', na_values='?')\n",
        "\n",
        "data_age.drop(data_age.filter(like='measured').columns, axis=1, inplace=True)\n",
        "data_age.drop('[record identification]', axis=1, inplace=True)\n",
        "data_age.drop('referral source:',axis=1,inplace=True)\n",
        "data_age.dropna(subset=['age:'],inplace=True)\n",
        "\n",
        "for i in range(len(data_age)):\n",
        "    if data_age.at[i, \"diagnoses\"] in hyperthyroid_conditions :\n",
        "        data_age.at[i, \"diagnoses\"] = 1\n",
        "    elif data_age.at[i, \"diagnoses\"] in hypothyroid_conditions :\n",
        "        data_age.at[i, \"diagnoses\"] = 2\n",
        "    elif data_age.at[i, \"diagnoses\"] in binding_protein :\n",
        "        data_age.at[i, \"diagnoses\"] = 3\n",
        "    elif data_age.at[i, \"diagnoses\"] in general_health :\n",
        "        data_age.at[i, \"diagnoses\"] = 4\n",
        "    elif data_age.at[i, \"diagnoses\"] in replacement_therapy :\n",
        "        data_age.at[i, \"diagnoses\"] = 5\n",
        "    elif data_age.at[i, \"diagnoses\"] in discordant :\n",
        "        data_age.at[i, \"diagnoses\"] = 6\n",
        "    elif data_age.at[i, \"diagnoses\"] in none :\n",
        "        data_age.at[i, \"diagnoses\"] = 7\n",
        "    else:\n",
        "        data_age.at[i, \"diagnoses\"] = 8 \n",
        "\n",
        "data_age.replace('f', 0, inplace=True)\n",
        "data_age.replace('t', 1, inplace=True)\n",
        "data_age.replace('F', 0, inplace=True)\n",
        "data_age.replace('M', 1, inplace=True)\n",
        "\n",
        "X_age = data_age.iloc[:,1:]\n",
        "y_age = data_age.iloc[: , :1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_age, y_age, test_size=0.25,random_state=0)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "Xt_train=scaler.fit_transform(X_train)\n",
        "Xt_test=scaler.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81b36357",
      "metadata": {},
      "source": [
        "### SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1077ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "model = SVR()\n",
        "\n",
        "print(\"02AGE SVR sem valores Nan, com scaler:\")\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "model.fit(X_train_imputed, y_train)\n",
        "\n",
        "preds = model.predict(X_test_imputed)\n",
        "print(\"R2 Score:\",r2_score(y_test, preds))\n",
        "\n",
        "y_train_flat = np.ravel(y_train)\n",
        "y_test_flat = np.ravel(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "295566fe",
      "metadata": {},
      "source": [
        "## Best Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4ef2c9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "rfr.fit(X_train_imputed, y_train)\n",
        "\n",
        "# Calculate feature importances and standard deviations\n",
        "importances = rfr.feature_importances_\n",
        "std = np.std([t.feature_importances_ for t in rfr.estimators_], axis=0)\n",
        "\n",
        "# Sort features based on importances\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print and plot feature importances with error bars\n",
        "print(\"Feature Importances:\")\n",
        "for f in range(X_train_imputed.shape[1]):\n",
        "    print(\"%d: Feature %d (%f ± %f)\" % (f + 1, indices[f], importances[indices[f]], std[indices[f]]))\n",
        "    \n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(X_train_imputed.shape[1]), importances[indices], color=\"b\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X_train_imputed.shape[1]), X_age.columns[indices], rotation=90)\n",
        "plt.xlim([-1, X_train_imputed.shape[1]])\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.title(\"Feature Importances with Error Bars\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6bf75ed",
      "metadata": {},
      "source": [
        "## Sexo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a211606",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# OBJETIVO 2: SEX\n",
        "\n",
        "data_sex = pd.read_csv('proj-data.csv', na_values='?')\n",
        "\n",
        "data_sex.drop(data_sex.filter(like='measured').columns, axis=1, inplace=True)\n",
        "data_sex.drop('[record identification]', axis=1, inplace=True)\n",
        "data_sex.drop('referral source:', axis=1, inplace=True)\n",
        "data_sex.dropna(subset=['sex:'], inplace=True)\n",
        "\n",
        "# Reset index after dropping rows with NaN values\n",
        "data_sex.reset_index(drop=True, inplace=True)\n",
        "\n",
        "for i in range(len(data_sex)):\n",
        "    if data_sex.at[i, \"diagnoses\"] in hyperthyroid_conditions:\n",
        "        data_sex.at[i, \"diagnoses\"] = 1\n",
        "    elif data_sex.at[i, \"diagnoses\"] in hypothyroid_conditions:\n",
        "        data_sex.at[i, \"diagnoses\"] = 2\n",
        "    elif data_sex.at[i, \"diagnoses\"] in binding_protein:\n",
        "        data_sex.at[i, \"diagnoses\"] = 3\n",
        "    elif data_sex.at[i, \"diagnoses\"] in general_health:\n",
        "        data_sex.at[i, \"diagnoses\"] = 4\n",
        "    elif data_sex.at[i, \"diagnoses\"] in replacement_therapy:\n",
        "        data_sex.at[i, \"diagnoses\"] = 5\n",
        "    elif data_sex.at[i, \"diagnoses\"] in discordant:\n",
        "        data_sex.at[i, \"diagnoses\"] = 6\n",
        "    elif data_sex.at[i, \"diagnoses\"] in none:\n",
        "        data_sex.at[i, \"diagnoses\"] = 7\n",
        "    else:\n",
        "        data_sex.at[i, \"diagnoses\"] = 8\n",
        "\n",
        "data_sex.replace('f', 0, inplace=True)\n",
        "data_sex.replace('t', 1, inplace=True)\n",
        "data_sex.replace('F', 0, inplace=True)\n",
        "data_sex.replace('M', 1, inplace=True)\n",
        "\n",
        "X_sex = data_sex.iloc[:, :]\n",
        "X_sex.drop('sex:', axis=1, inplace=True)\n",
        "\n",
        "y_sex = data_sex[['sex:']]  # Extract 'sex:' column for y_sex\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sex, y_sex, test_size=0.25, random_state=0)\n",
        "\n",
        "# Ensure y_train and y_test are in the correct shape for fitting the model\n",
        "y_train_flat = y_train.values.ravel()\n",
        "y_test_flat = y_test.values.ravel()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cc7f211",
      "metadata": {},
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80ee0637",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize imputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Impute and scale the data\n",
        "print(\"02SEX KNN tree usando um scaler:\")\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train_scaled)\n",
        "X_test_imputed = imputer.transform(X_test_scaled)\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors=7)\n",
        "knn_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "knn_preds = knn_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, knn_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "570de75a",
      "metadata": {},
      "source": [
        "## Best Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cddbbcc4",
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier(random_state=123)      \n",
        "rfc.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "# Calculate feature importances and standard deviations\n",
        "importances = rfc.feature_importances_\n",
        "std = np.std([t.feature_importances_ for t in rfc.estimators_], axis=0)\n",
        "\n",
        "# Sort features based on importances\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print and plot feature importances with error bars\n",
        "print(\"Feature Importances:\")\n",
        "for f in range(X_train_imputed.shape[1]):\n",
        "    print(\"%d: Feature %d (%f ± %f)\" % (f + 1, indices[f], importances[indices[f]], std[indices[f]]))\n",
        "    \n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(X_train_imputed.shape[1]), importances[indices], color=\"b\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X_train_imputed.shape[1]), X_sex.columns[indices], rotation=90)\n",
        "plt.xlim([-1, X_train_imputed.shape[1]])\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.title(\"Feature Importances with Error Bars\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "771b4d1d",
      "metadata": {},
      "source": [
        "# Célula final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a1e95161",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores do teste:\n",
            "[7 7 7 7 4 7 7 7 7 7 1 7 7 7 7 7 7 2 7 2]\n",
            "Valores da previsão:\n",
            "[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 2]\n",
            "Statistics:\n",
            "The Precision is:  0.7737\n",
            "The Accuracy is:  0.8500\n",
            "The Recall is:  0.8500\n",
            "The F1 score is:  0.7981\n",
            "The Matthews correlation coefficient is:  0.4695\n",
            "-------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Duarte\\AppData\\Local\\Temp\\ipykernel_5556\\1428948878.py:67: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  data.replace('f', 0, inplace=True)\n",
            "C:\\Users\\Duarte\\AppData\\Local\\Temp\\ipykernel_5556\\1428948878.py:68: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  data.replace('t', 1, inplace=True)\n",
            "C:\\Users\\Duarte\\AppData\\Local\\Temp\\ipykernel_5556\\1428948878.py:70: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  data.replace('M', 1, inplace=True)\n",
            "C:\\Users\\Duarte\\AppData\\Local\\Temp\\ipykernel_5556\\1428948878.py:90: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  testData.replace('f', 0, inplace=True)\n",
            "C:\\Users\\Duarte\\AppData\\Local\\Temp\\ipykernel_5556\\1428948878.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  testData.replace('t', 1, inplace=True)\n",
            "C:\\Users\\Duarte\\AppData\\Local\\Temp\\ipykernel_5556\\1428948878.py:93: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  testData.replace('M', 1, inplace=True)\n",
            "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, matthews_corrcoef, make_scorer\n",
        "\n",
        "\n",
        "def present_statistics(y_test, preds):\n",
        "    print(\"Statistics:\")\n",
        "    print(\"The Precision is: %7.4f\" % precision_score(y_test, preds, average='weighted'))\n",
        "    print(\"The Accuracy is: %7.4f\" % accuracy_score(y_test, preds))\n",
        "    print(\"The Recall is: %7.4f\" % recall_score(y_test, preds, average='weighted'))\n",
        "    print(\"The F1 score is: %7.4f\" % f1_score(y_test, preds, average='weighted'))\n",
        "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(y_test, preds))\n",
        "    print(\"-------------------------------------------------------------\")\n",
        "\n",
        "data = pd.read_csv('proj-data.csv', na_values='?')\n",
        "testData = pd.read_csv('proj-test-data.csv', na_values='?')\n",
        "testClass = pd.read_csv('proj-test-class.csv', na_values='?')\n",
        "\n",
        "data.drop(data.filter(like='measured').columns, axis=1, inplace=True)\n",
        "data.drop('[record identification]', axis=1, inplace=True)\n",
        "data.drop('referral source:',axis=1,inplace=True)\n",
        "\n",
        "hyperthyroid_conditions = ['A', 'B', 'C', 'D']\n",
        "hypothyroid_conditions = ['E', 'F', 'G', 'H']\n",
        "binding_protein = ['I', 'J']\n",
        "general_health = ['K']\n",
        "replacement_therapy = ['L', 'M', 'N']\n",
        "discordant = ['R']\n",
        "none = ['-']\n",
        "\n",
        "for i in range(len(data)):\n",
        "    if data.at[i, \"diagnoses\"] in hyperthyroid_conditions :\n",
        "        data.at[i, \"diagnoses\"] = 1\n",
        "    elif data.at[i, \"diagnoses\"] in hypothyroid_conditions :\n",
        "        data.at[i, \"diagnoses\"] = 2\n",
        "    elif data.at[i, \"diagnoses\"] in binding_protein :\n",
        "        data.at[i, \"diagnoses\"] = 3\n",
        "    elif data.at[i, \"diagnoses\"] in general_health :\n",
        "        data.at[i, \"diagnoses\"] = 4\n",
        "    elif data.at[i, \"diagnoses\"] in replacement_therapy :\n",
        "        data.at[i, \"diagnoses\"] = 5\n",
        "    elif data.at[i, \"diagnoses\"] in discordant :\n",
        "        data.at[i, \"diagnoses\"] = 6\n",
        "    elif data.at[i, \"diagnoses\"] in none :\n",
        "        data.at[i, \"diagnoses\"] = 7 \n",
        "    else:\n",
        "        data.at[i, \"diagnoses\"] = 8 \n",
        "\n",
        "for i in range(len(testClass)):\n",
        "    if testClass.at[i, \"diagnoses\"] in hyperthyroid_conditions :\n",
        "        testClass.at[i, \"diagnoses\"] = 1\n",
        "    elif testClass.at[i, \"diagnoses\"] in hypothyroid_conditions :\n",
        "        testClass.at[i, \"diagnoses\"] = 2\n",
        "    elif testClass.at[i, \"diagnoses\"] in binding_protein :\n",
        "        testClass.at[i, \"diagnoses\"] = 3\n",
        "    elif testClass.at[i, \"diagnoses\"] in general_health :\n",
        "        testClass.at[i, \"diagnoses\"] = 4\n",
        "    elif testClass.at[i, \"diagnoses\"] in replacement_therapy :\n",
        "        testClass.at[i, \"diagnoses\"] = 5\n",
        "    elif testClass.at[i, \"diagnoses\"] in discordant :\n",
        "        testClass.at[i, \"diagnoses\"] = 6\n",
        "    elif testClass.at[i, \"diagnoses\"] in none :\n",
        "        testClass.at[i, \"diagnoses\"] = 7 \n",
        "    else:\n",
        "        testClass.at[i, \"diagnoses\"] = 8 \n",
        "\n",
        "data.replace('f', 0, inplace=True)\n",
        "data.replace('t', 1, inplace=True)\n",
        "data.replace('F', 0, inplace=True)\n",
        "data.replace('M', 1, inplace=True)\n",
        "\n",
        "X = data.iloc[:,:-1]\n",
        "\n",
        "y = data.iloc[: , -1:]\n",
        "y = y.astype('int')\n",
        "\n",
        "\n",
        "X = data.iloc[:,:-1]\n",
        "\n",
        "y = data.iloc[: , -1:]\n",
        "y = y.astype('int')\n",
        "\n",
        "tree_model = DecisionTreeClassifier(criterion = 'entropy', max_depth = 27, max_features = None, min_samples_leaf = 2, min_samples_split = 6)\n",
        "tree_model.fit(X, y)\n",
        "\n",
        "testData.drop(testData.filter(like='measured').columns, axis=1, inplace=True)\n",
        "testData.drop('[record identification]', axis=1, inplace=True)\n",
        "testData.drop('referral source:',axis=1,inplace=True)\n",
        "\n",
        "testData.replace('f', 0, inplace=True)\n",
        "testData.replace('t', 1, inplace=True)\n",
        "testData.replace('F', 0, inplace=True)\n",
        "testData.replace('M', 1, inplace=True)\n",
        "\n",
        "# Make predictions\n",
        "tree_preds = tree_model.predict(testData)\n",
        "testClass_flat = testClass['diagnoses'].astype(int).values.flatten()\n",
        "print(\"Valores do teste:\")\n",
        "print(testClass_flat)\n",
        "print(\"Valores da previsão:\")\n",
        "print(tree_preds)\n",
        "present_statistics(testClass_flat, tree_preds)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.11.0rc1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
