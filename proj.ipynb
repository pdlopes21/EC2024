{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3a52d395",
      "metadata": {},
      "source": [
        "# Projeto de Engenharia do Conhecimento 2023/2024\n",
        "\n",
        "*Projeto by: Renato Ferreira (58238), Pedro Lopes(58196), SimÃ£o Quintas (58190)*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bfdaccd",
      "metadata": {},
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "13b219f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, matthews_corrcoef, make_scorer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d8ae247e",
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'proj-data.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproj-data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, na_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m.\u001b[39mdrop(data\u001b[38;5;241m.\u001b[39mfilter(like\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeasured\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[record identification]\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
            "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'proj-data.csv'"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('proj-data.csv', na_values='?')\n",
        "\n",
        "data.drop(data.filter(like='measured').columns, axis=1, inplace=True)\n",
        "data.drop('[record identification]', axis=1, inplace=True)\n",
        "data.drop('referral source:',axis=1,inplace=True)\n",
        "\n",
        "hyperthyroid_conditions = ['A', 'B', 'C', 'D']\n",
        "hypothyroid_conditions = ['E', 'F', 'G', 'H']\n",
        "binding_protein = ['I', 'J']\n",
        "general_health = ['K']\n",
        "replacement_therapy = ['L', 'M', 'N']\n",
        "discordant = ['R']\n",
        "none = ['-']\n",
        "\n",
        "for i in range(len(data)):\n",
        "    if data.at[i, \"diagnoses\"] in hyperthyroid_conditions :\n",
        "        data.at[i, \"diagnoses\"] = 1\n",
        "    elif data.at[i, \"diagnoses\"] in hypothyroid_conditions :\n",
        "        data.at[i, \"diagnoses\"] = 2\n",
        "    elif data.at[i, \"diagnoses\"] in binding_protein :\n",
        "        data.at[i, \"diagnoses\"] = 3\n",
        "    elif data.at[i, \"diagnoses\"] in general_health :\n",
        "        data.at[i, \"diagnoses\"] = 4\n",
        "    elif data.at[i, \"diagnoses\"] in replacement_therapy :\n",
        "        data.at[i, \"diagnoses\"] = 5\n",
        "    elif data.at[i, \"diagnoses\"] in discordant :\n",
        "        data.at[i, \"diagnoses\"] = 6\n",
        "    elif data.at[i, \"diagnoses\"] in none :\n",
        "        data.at[i, \"diagnoses\"] = 7 \n",
        "    else:\n",
        "        data.at[i, \"diagnoses\"] = 8 \n",
        "\n",
        "data.replace('f', 0, inplace=True)\n",
        "data.replace('t', 1, inplace=True)\n",
        "data.replace('F', 0, inplace=True)\n",
        "data.replace('M', 1, inplace=True)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea2fb48",
      "metadata": {},
      "outputs": [],
      "source": [
        "missingValues = {}\n",
        "for i in data.values:\n",
        "  c=0\n",
        "  for j in i:\n",
        "    if pd.isna(j):\n",
        "      if data.columns[c] not in missingValues:\n",
        "        missingValues[data.columns[c]] = 1\n",
        "      else:\n",
        "        missingValues[data.columns[c]] += 1\n",
        "    c+=1\n",
        "\n",
        "for c in missingValues.keys():\n",
        "  if missingValues[c] > 0:\n",
        "    print(c,str(missingValues[c]),\"missing values!\")\n",
        "\n",
        "X = data.iloc[:,:-1]\n",
        "y = data.iloc[: , -1:]\n",
        "y = y.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2725fe8",
      "metadata": {},
      "source": [
        "Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ebd5bc5",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=0)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "Xt_train=scaler.fit_transform(X_train)\n",
        "Xt_test=scaler.fit_transform(X_test)\n",
        "N,M = Xt_train.shape\n",
        "\n",
        "rfr=RandomForestRegressor(random_state=0)\n",
        "sel = SelectFromModel(estimator=rfr,threshold=0.02)\n",
        "y_train = y_train.squeeze().ravel()\n",
        "y_test = y_test.squeeze().ravel()\n",
        "sel.fit(Xt_train, y_train)\n",
        "print(\"Default threshold: \", sel.threshold_)\n",
        "\n",
        "features=sel.get_support()\n",
        "Features_selected =np.arange(M)[features]\n",
        "print(\"The features selected are columns: \", Features_selected)\n",
        "\n",
        "nX_train=sel.transform(Xt_train)\n",
        "nX_test=sel.transform(Xt_test)\n",
        "score = make_scorer(matthews_corrcoef)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d12a6a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier(random_state=123)      \n",
        "rfc.fit(Xt_train, y_train)\n",
        "\n",
        "importances = rfc.feature_importances_\n",
        "std = np.std([t.feature_importances_ for t in rfc.estimators_], axis=0)\n",
        "\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "print(\"Feature Importances:\")\n",
        "for f in range(Xt_train.shape[1]):\n",
        "    print(\"%d: Feature %d (%f Â± %f)\" % (f + 1, indices[f], importances[indices[f]], std[indices[f]]))\n",
        "    \n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(Xt_train.shape[1]), importances[indices], color=\"b\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(Xt_train.shape[1]), X.columns[indices], rotation=90)\n",
        "plt.xlim([-1, Xt_train.shape[1]])\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.title(\"Feature Importances with Error Bars\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff275eb4",
      "metadata": {},
      "source": [
        "### MÃ©todos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59e5daae",
      "metadata": {},
      "outputs": [],
      "source": [
        "def present_statistics(y_test, preds):\n",
        "    print(\"Statistics:\")\n",
        "    print(\"The Precision is: %7.4f\" % precision_score(y_test, preds, average='weighted'))\n",
        "    print(\"The Accuracy is: %7.4f\" % accuracy_score(y_test, preds))\n",
        "    print(\"The Recall is: %7.4f\" % recall_score(y_test, preds, average='weighted'))\n",
        "    print(\"The F1 score is: %7.4f\" % f1_score(y_test, preds, average='weighted'))\n",
        "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(y_test, preds))\n",
        "    print(\"-------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d212e6b8",
      "metadata": {},
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c4d0cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "print(\"Com valores Nan, sem scaler:\")\n",
        "tree_model = DecisionTreeClassifier()\n",
        "tree_model.fit(X_train, y_train)\n",
        "tree_preds = tree_model.predict(X_test)\n",
        "present_statistics(y_test, tree_preds)\n",
        "\n",
        "print(\"Sem valores Nan, sem scaler:\")\n",
        "imputer = SimpleImputer(strategy='constant', fill_value=-1)\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "tree_model.fit(X_train_imputed, y_train)\n",
        "tree_preds = tree_model.predict(X_test_imputed)\n",
        "present_statistics(y_test, tree_preds)\n",
        "\n",
        "print(\"Com valores Nan, com scaler:\")\n",
        "tree_model.fit(Xt_train, y_train)\n",
        "tree_preds = tree_model.predict(Xt_test)\n",
        "present_statistics(y_test, tree_preds)\n",
        "\n",
        "print(\"Sem valores Nan, com scaler:\")\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "tree_model.fit(X_train_imputed, y_train)\n",
        "tree_preds = tree_model.predict(X_test_imputed)\n",
        "present_statistics(y_test, tree_preds)\n",
        "\n",
        "y_train_flat = np.ravel(y_train)\n",
        "y_test_flat = np.ravel(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf2f559b",
      "metadata": {},
      "source": [
        "KNeighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02fdfd13",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "print(\"Usando um scaler:\")\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "knn_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "knn_preds = knn_model.predict(X_test_imputed)\n",
        "present_statistics(y_test, knn_preds)\n",
        "\n",
        "print(\"Sem usar scaler:\")\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "knn_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "knn_preds = knn_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, knn_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f97f89c",
      "metadata": {},
      "source": [
        "SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "897724dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "svc_model = SVC()\n",
        "\n",
        "print(svc_model,\"usando scaler:\")\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "svc_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "svc_preds = svc_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, svc_preds)\n",
        "\n",
        "print(svc_model,\"sem scaler:\")\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "svc_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "svc_preds = svc_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, svc_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6381e11c",
      "metadata": {},
      "source": [
        "Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8627910d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gaus_model = GaussianNB()\n",
        "\n",
        "print(gaus_model,\"sem scaler:\")\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "gaus_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "gaus_preds = gaus_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, gaus_preds)\n",
        "\n",
        "print(gaus_model,\"com scaler:\")\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "gaus_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "gaus_preds = gaus_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, gaus_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83936bfe",
      "metadata": {},
      "source": [
        "LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f89254",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logr_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "print(logr_model,\"com scaler:\")\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "logr_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "logr_preds = logr_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, logr_preds)\n",
        "\n",
        "print(logr_model,\"sem scaler:\")\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "logr_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "logr_preds = logr_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, logr_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75163cfc",
      "metadata": {},
      "source": [
        "Model Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a05b584b",
      "metadata": {},
      "source": [
        "Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "995c07b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'max_depth': [None,*range(3, 30)],\n",
        "    'min_samples_split': [*range(2,15)],\n",
        "    'min_samples_leaf': [*range(2,15)],\n",
        "    'max_features': [None],\n",
        "    'criterion': ['gini','entropy']\n",
        "}\n",
        "\n",
        "tree_model = DecisionTreeClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(estimator=tree_model, param_grid=param_grid, cv=5, scoring='f1_macro')\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_tree_model = grid_search.best_estimator_\n",
        "\n",
        "tree_preds = best_tree_model.predict(X_test)\n",
        "\n",
        "present_statistics(y_test, tree_preds)\n",
        "\n",
        "cv_scores = cross_val_score(best_tree_model, X_train, y_train, cv=5, scoring='f1_macro')\n",
        "\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean Cross-Validation Score:\", cv_scores.mean())\n",
        "print(\"Standard Deviation of Cross-Validation Score:\", cv_scores.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36575ef1",
      "metadata": {},
      "source": [
        "KNeighbours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3760f466",
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_neighbors': [3,5,7,9,11,13,15,17],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
        "}\n",
        "\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=5, scoring='f1_weighted')\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "grid_search.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_knn_model = grid_search.best_estimator_\n",
        "\n",
        "knn_preds = best_knn_model.predict(X_test_imputed)\n",
        "\n",
        "present_statistics(y_test_flat, knn_preds)\n",
        "\n",
        "cv_scores = cross_val_score(best_knn_model, X_train_imputed, y_train_flat, cv=5, scoring='f1_macro')\n",
        "\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean Cross-Validation Score:\", cv_scores.mean())\n",
        "print(\"Standard Deviation of Cross-Validation Score:\", cv_scores.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77482137",
      "metadata": {},
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19e3929b",
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "logreg_model = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\n",
        "\n",
        "grid_search = GridSearchCV(estimator=logreg_model, param_grid=param_grid, cv=5, scoring='f1_weighted')\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "grid_search.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_logreg_model = grid_search.best_estimator_\n",
        "\n",
        "logreg_preds = best_logreg_model.predict(X_test_imputed)\n",
        "\n",
        "present_statistics(y_test_flat, logreg_preds)\n",
        "\n",
        "cv_scores = cross_val_score(best_logreg_model, X_train_imputed, y_train_flat, cv=5, scoring='f1_macro')\n",
        "\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean Cross-Validation Score:\", cv_scores.mean())\n",
        "print(\"Standard Deviation of Cross-Validation Score:\", cv_scores.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31d0cb85",
      "metadata": {},
      "source": [
        "O2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8db72f60",
      "metadata": {},
      "source": [
        "Idade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adfb6ea2",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "data_age = pd.read_csv('proj-data.csv', na_values='?')\n",
        "\n",
        "data_age.drop(data_age.filter(like='measured').columns, axis=1, inplace=True)\n",
        "data_age.drop('[record identification]', axis=1, inplace=True)\n",
        "data_age.drop('referral source:',axis=1,inplace=True)\n",
        "data_age.dropna(subset=['age:'],inplace=True)\n",
        "\n",
        "for i in range(len(data_age)):\n",
        "    if data_age.at[i, \"diagnoses\"] in hyperthyroid_conditions :\n",
        "        data_age.at[i, \"diagnoses\"] = 1\n",
        "    elif data_age.at[i, \"diagnoses\"] in hypothyroid_conditions :\n",
        "        data_age.at[i, \"diagnoses\"] = 2\n",
        "    elif data_age.at[i, \"diagnoses\"] in binding_protein :\n",
        "        data_age.at[i, \"diagnoses\"] = 3\n",
        "    elif data_age.at[i, \"diagnoses\"] in general_health :\n",
        "        data_age.at[i, \"diagnoses\"] = 4\n",
        "    elif data_age.at[i, \"diagnoses\"] in replacement_therapy :\n",
        "        data_age.at[i, \"diagnoses\"] = 5\n",
        "    elif data_age.at[i, \"diagnoses\"] in discordant :\n",
        "        data_age.at[i, \"diagnoses\"] = 6\n",
        "    elif data_age.at[i, \"diagnoses\"] in none :\n",
        "        data_age.at[i, \"diagnoses\"] = 7\n",
        "    else:\n",
        "        data_age.at[i, \"diagnoses\"] = 8 \n",
        "\n",
        "data_age.replace('f', 0, inplace=True)\n",
        "data_age.replace('t', 1, inplace=True)\n",
        "data_age.replace('F', 0, inplace=True)\n",
        "data_age.replace('M', 1, inplace=True)\n",
        "\n",
        "X_age = data_age.iloc[:,1:]\n",
        "y_age = data_age.iloc[: , :1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_age, y_age, test_size=0.25,random_state=0)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "Xt_train=scaler.fit_transform(X_train)\n",
        "Xt_test=scaler.fit_transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "model = SVR()\n",
        "\n",
        "print(\"02AGE SVR sem valores Nan, com scaler:\")\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(Xt_train)\n",
        "X_test_imputed = imputer.transform(Xt_test)\n",
        "\n",
        "model.fit(X_train_imputed, y_train)\n",
        "\n",
        "preds = model.predict(X_test_imputed)\n",
        "print(\"R2 Score:\",r2_score(y_test, preds))\n",
        "\n",
        "y_train_flat = np.ravel(y_train)\n",
        "y_test_flat = np.ravel(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "295566fe",
      "metadata": {},
      "source": [
        "Best Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4ef2c9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "rfr.fit(X_train_imputed, y_train)\n",
        "\n",
        "importances = rfr.feature_importances_\n",
        "std = np.std([t.feature_importances_ for t in rfr.estimators_], axis=0)\n",
        "\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "print(\"Feature Importances:\")\n",
        "for f in range(X_train_imputed.shape[1]):\n",
        "    print(\"%d: Feature %d (%f Â± %f)\" % (f + 1, indices[f], importances[indices[f]], std[indices[f]]))\n",
        "    \n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(X_train_imputed.shape[1]), importances[indices], color=\"b\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X_train_imputed.shape[1]), X_age.columns[indices], rotation=90)\n",
        "plt.xlim([-1, X_train_imputed.shape[1]])\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.title(\"Feature Importances with Error Bars\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6bf75ed",
      "metadata": {},
      "source": [
        "Sexo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a211606",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data_sex = pd.read_csv('proj-data.csv', na_values='?')\n",
        "\n",
        "data_sex.drop(data_sex.filter(like='measured').columns, axis=1, inplace=True)\n",
        "data_sex.drop('[record identification]', axis=1, inplace=True)\n",
        "data_sex.drop('referral source:', axis=1, inplace=True)\n",
        "data_sex.dropna(subset=['sex:'], inplace=True)\n",
        "\n",
        "data_sex.reset_index(drop=True, inplace=True)\n",
        "\n",
        "for i in range(len(data_sex)):\n",
        "    if data_sex.at[i, \"diagnoses\"] in hyperthyroid_conditions:\n",
        "        data_sex.at[i, \"diagnoses\"] = 1\n",
        "    elif data_sex.at[i, \"diagnoses\"] in hypothyroid_conditions:\n",
        "        data_sex.at[i, \"diagnoses\"] = 2\n",
        "    elif data_sex.at[i, \"diagnoses\"] in binding_protein:\n",
        "        data_sex.at[i, \"diagnoses\"] = 3\n",
        "    elif data_sex.at[i, \"diagnoses\"] in general_health:\n",
        "        data_sex.at[i, \"diagnoses\"] = 4\n",
        "    elif data_sex.at[i, \"diagnoses\"] in replacement_therapy:\n",
        "        data_sex.at[i, \"diagnoses\"] = 5\n",
        "    elif data_sex.at[i, \"diagnoses\"] in discordant:\n",
        "        data_sex.at[i, \"diagnoses\"] = 6\n",
        "    elif data_sex.at[i, \"diagnoses\"] in none:\n",
        "        data_sex.at[i, \"diagnoses\"] = 7\n",
        "    else:\n",
        "        data_sex.at[i, \"diagnoses\"] = 8\n",
        "\n",
        "data_sex.replace('f', 0, inplace=True)\n",
        "data_sex.replace('t', 1, inplace=True)\n",
        "data_sex.replace('F', 0, inplace=True)\n",
        "data_sex.replace('M', 1, inplace=True)\n",
        "\n",
        "X_sex = data_sex.iloc[:, :]\n",
        "X_sex.drop('sex:', axis=1, inplace=True)\n",
        "\n",
        "y_sex = data_sex[['sex:']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sex, y_sex, test_size=0.25, random_state=0)\n",
        "\n",
        "y_train_flat = y_train.values.ravel()\n",
        "y_test_flat = y_test.values.ravel()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cc7f211",
      "metadata": {},
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80ee0637",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "print(\"02SEX KNN tree usando um scaler:\")\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train_scaled)\n",
        "X_test_imputed = imputer.transform(X_test_scaled)\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors=7)\n",
        "knn_model.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "knn_preds = knn_model.predict(X_test_imputed)\n",
        "present_statistics(y_test_flat, knn_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "570de75a",
      "metadata": {},
      "source": [
        "Best Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cddbbcc4",
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier(random_state=123)      \n",
        "rfc.fit(X_train_imputed, y_train_flat)\n",
        "\n",
        "importances = rfc.feature_importances_\n",
        "std = np.std([t.feature_importances_ for t in rfc.estimators_], axis=0)\n",
        "\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "print(\"Feature Importances:\")\n",
        "for f in range(X_train_imputed.shape[1]):\n",
        "    print(\"%d: Feature %d (%f Â± %f)\" % (f + 1, indices[f], importances[indices[f]], std[indices[f]]))\n",
        "    \n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(X_train_imputed.shape[1]), importances[indices], color=\"b\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X_train_imputed.shape[1]), X_sex.columns[indices], rotation=90)\n",
        "plt.xlim([-1, X_train_imputed.shape[1]])\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.title(\"Feature Importances with Error Bars\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "771b4d1d",
      "metadata": {},
      "source": [
        "CÃ©lula final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1e95161",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = pd.read_csv('proj-data.csv', na_values='?')\n",
        "testData = pd.read_csv('proj-test-data.csv', na_values='?')\n",
        "testClass = pd.read_csv('proj-test-class.csv', na_values='?')\n",
        "data.drop(data.filter(like='measured').columns, axis=1, inplace=True)\n",
        "data.drop('[record identification]', axis=1, inplace=True)\n",
        "data.drop('referral source:',axis=1,inplace=True)\n",
        "\n",
        "hyperthyroid_conditions = ['A', 'B', 'C', 'D']\n",
        "hypothyroid_conditions = ['E', 'F', 'G', 'H']\n",
        "binding_protein = ['I', 'J']\n",
        "general_health = ['K']\n",
        "replacement_therapy = ['L', 'M', 'N']\n",
        "discordant = ['R']\n",
        "none = ['-']\n",
        "\n",
        "for i in range(len(data)):\n",
        "    if data.at[i, \"diagnoses\"] in hyperthyroid_conditions :\n",
        "        data.at[i, \"diagnoses\"] = 1\n",
        "    elif data.at[i, \"diagnoses\"] in hypothyroid_conditions :\n",
        "        data.at[i, \"diagnoses\"] = 2\n",
        "    elif data.at[i, \"diagnoses\"] in binding_protein :\n",
        "        data.at[i, \"diagnoses\"] = 3\n",
        "    elif data.at[i, \"diagnoses\"] in general_health :\n",
        "        data.at[i, \"diagnoses\"] = 4\n",
        "    elif data.at[i, \"diagnoses\"] in replacement_therapy :\n",
        "        data.at[i, \"diagnoses\"] = 5\n",
        "    elif data.at[i, \"diagnoses\"] in discordant :\n",
        "        data.at[i, \"diagnoses\"] = 6\n",
        "    elif data.at[i, \"diagnoses\"] in none :\n",
        "        data.at[i, \"diagnoses\"] = 7 \n",
        "    else:\n",
        "        data.at[i, \"diagnoses\"] = 8 \n",
        "\n",
        "for i in range(len(testClass)):\n",
        "    if testClass.at[i, \"diagnoses\"] in hyperthyroid_conditions :\n",
        "        testClass.at[i, \"diagnoses\"] = 1\n",
        "    elif testClass.at[i, \"diagnoses\"] in hypothyroid_conditions :\n",
        "        testClass.at[i, \"diagnoses\"] = 2\n",
        "    elif testClass.at[i, \"diagnoses\"] in binding_protein :\n",
        "        testClass.at[i, \"diagnoses\"] = 3\n",
        "    elif testClass.at[i, \"diagnoses\"] in general_health :\n",
        "        testClass.at[i, \"diagnoses\"] = 4\n",
        "    elif testClass.at[i, \"diagnoses\"] in replacement_therapy :\n",
        "        testClass.at[i, \"diagnoses\"] = 5\n",
        "    elif testClass.at[i, \"diagnoses\"] in discordant :\n",
        "        testClass.at[i, \"diagnoses\"] = 6\n",
        "    elif testClass.at[i, \"diagnoses\"] in none :\n",
        "        testClass.at[i, \"diagnoses\"] = 7 \n",
        "    else:\n",
        "        testClass.at[i, \"diagnoses\"] = 8 \n",
        "\n",
        "data.replace('f', 0, inplace=True)\n",
        "data.replace('t', 1, inplace=True)\n",
        "data.replace('F', 0, inplace=True)\n",
        "data.replace('M', 1, inplace=True)\n",
        "\n",
        "X = data.iloc[:,:-1]\n",
        "y = data.iloc[: , -1:]\n",
        "y = y.astype('int')\n",
        "X = data.iloc[:,:-1]\n",
        "y = data.iloc[: , -1:]\n",
        "y = y.astype('int')\n",
        "\n",
        "tree_model = DecisionTreeClassifier(criterion = 'entropy', max_depth = 27, max_features = None, min_samples_leaf = 2, min_samples_split = 6)\n",
        "tree_model.fit(X, y)\n",
        "\n",
        "testData.drop(testData.filter(like='measured').columns, axis=1, inplace=True)\n",
        "testData.drop('[record identification]', axis=1, inplace=True)\n",
        "testData.drop('referral source:',axis=1,inplace=True)\n",
        "testData.replace('f', 0, inplace=True)\n",
        "testData.replace('t', 1, inplace=True)\n",
        "testData.replace('F', 0, inplace=True)\n",
        "testData.replace('M', 1, inplace=True)\n",
        "\n",
        "tree_preds = tree_model.predict(testData)\n",
        "testClass_flat = testClass['diagnoses'].astype(int).values.flatten()\n",
        "print(\"Valores do teste:\", testClass_flat)\n",
        "print(\"Valores da previsÃ£o:\", tree_preds)\n",
        "print(\"The Accuracy is: %7.4f\" % accuracy_score(y_test, preds))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.11.0rc1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
